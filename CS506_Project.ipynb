{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_H-LGChalxcK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "datasets_dir = '/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Data/contributions-2015-2016.csv' does not exist: b'/Data/contributions-2015-2016.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f5f6a21897e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcontributions_2016\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'contributions-2015-2016.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_contributions_2016\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcontributions_2016\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Data/contributions-2015-2016.csv' does not exist: b'/Data/contributions-2015-2016.csv'"
     ]
    }
   ],
   "source": [
    "contributions_2016 = 'contributions-2015-2016.csv'\n",
    "df_contributions_2016 = pd.read_csv(datasets_dir + contributions_2016, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statereps_2016 = 'State_Reps_2015-2016.csv'\n",
    "df_reps_2016 = pd.read_csv(datasets_dir + statereps_2016, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "NfPq8mbWlxcR",
    "outputId": "50538f67-f689-4a71-82dd-f2eac3c458f3"
   },
   "outputs": [],
   "source": [
    "contributions_2018 = 'contributions-2017-2018.csv'\n",
    "df_contributions_2018 = pd.read_csv(datasets_dir + contributions_2018, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statereps_2018 = 'State_Reps_2017-2018.csv'\n",
    "df_reps_2018 = pd.read_csv(datasets_dir + statereps_2018, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jlyp_Pt0lxcZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get list of all elected Candidates from 2015-2018\n",
    "reps = [df_reps_2016, df_reps_2018]\n",
    "df_reps = pd.concat(reps, sort=True)\n",
    "state_reps = list(df_reps['Representative'].unique())\n",
    "\n",
    "# Deallocate memory\n",
    "reps = []\n",
    "df_reps_2016 = []\n",
    "df_reps_2018 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine all contributions from 2015-2018\n",
    "contributions = [df_contributions_2016, df_contributions_2018]\n",
    "df_contributions = pd.concat(contributions, sort=True)\n",
    "\n",
    "# Deallocate memory\n",
    "contributions = []\n",
    "df_contributions_2016 = []\n",
    "df_contributions_2018 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsBMxplnlxce",
    "outputId": "adac16ce-a40d-435c-db7b-893e7066bb58"
   },
   "outputs": [],
   "source": [
    "display(len(state_reps))\n",
    "display(df_contributions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018_real = df_contributions.loc[df_contributions.Full_Name.isin(state_reps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new Donor_Name column that will allow easier analysis here\n",
    "# and moving forward\n",
    "\n",
    "import math\n",
    "\n",
    "def donor_name(first_name, last_name):\n",
    "    donor_name = ''\n",
    "    if (type(first_name) == str):\n",
    "        donor_name += first_name.upper().replace(\":-,.'\", ' ') + ' '\n",
    "    if (type(last_name) == str):\n",
    "        donor_name += last_name.upper().replace(\":-,.'\", ' ')\n",
    "    return donor_name\n",
    "\n",
    "df_2018_real['Donor_Name'] = df_2018_real[['First_Name', 'Last_Name']].apply(lambda x: donor_name(x[0], x[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Regular Expression Search for each Industry\n",
    "\n",
    "# Law Enforcement\n",
    "law_enforcement_keywords = ['law enforcement', 'district attorney', 'prosecutor', 'detective', 'trooper', 'probation officer', 'sheriff', 'correction', 'prison', 'patrolm[ae]n']\n",
    "law_enforcement_regex = ''\n",
    "\n",
    "for line in law_enforcement_keywords:\n",
    "    law_enforcement_regex += '(' + line +')|'\n",
    "\n",
    "law_enforcement_regex += '(police)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education\n",
    "education_keywords = ['teacher', 'educator', 'university', 'school', 'college', 'tutor', 'tuition', 'academ(y|ic)']\n",
    "education_regex = ''\n",
    "\n",
    "for line in education_keywords:\n",
    "    education_regex += '(' + line +')|'\n",
    "\n",
    "education_regex += '(education)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Estate\n",
    "realestate_keywords = ['realtor', 'realty', 'housing', 'leasing', '[^(it)|^(software)|^(data)] developer', '[^(it)|^(software)|^(data)] architect', 'construction', 'lodging', 'propert(y|ies)', 'residential', 'contractor']\n",
    "realestate_regex = ''\n",
    "\n",
    "for line in realestate_keywords:\n",
    "    realestate_regex += '(' + line +')|'\n",
    "\n",
    "realestate_regex += '(real estate)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Healthcare\n",
    "# Note - 'opthalm', 'urolog', 'chiropract', 'psychiatr' are added to match root words of medical specializations\n",
    "healthcare_keywords = ['health care', 'health', 'medical', 'hospital', 'nurse', 'rehab', 'nursing', 'clinic', 'doctor', 'psychologist', 'surgeon', 'dental', 'dentist', 'physician', 'opthalm', 'urolog', 'pharmacist', 'eye care', 'eye center', 'chiropract', 'psychiatr', '\\wem[ts]\\w', 'ambul[ae]nce', 'emergency']\n",
    "healthcare_regex = ''\n",
    "\n",
    "for line in healthcare_keywords:\n",
    "    healthcare_regex += '(' + line +')|'\n",
    "\n",
    "healthcare_regex += '(healthcare)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BioTech / Pharma\n",
    "biotech_keywords = ['genetech', 'bioscience']\n",
    "biotech_regex = ''\n",
    "\n",
    "for line in biotech_keywords:\n",
    "    biotech_regex += '(' + line +')|'\n",
    "\n",
    "biotech_regex += '(bio science)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy\n",
    "energy_keywords = ['eversource', 'sunpower', '\\wgrid\\w', '\\wwind\\w', '\\wsolar\\w']\n",
    "energy_regex = ''\n",
    "\n",
    "for line in energy_keywords:\n",
    "    energy_regex += '(' + line +')|'\n",
    "\n",
    "energy_regex += '(energy)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirees\n",
    "retiree_keywords = ['retire']\n",
    "retiree_regex = ''\n",
    "\n",
    "for line in retiree_keywords:\n",
    "    retiree_regex += '(' + line +')|'\n",
    "\n",
    "retiree_regex += '(retire)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-employed\n",
    "self_employed_keywords = ['self']\n",
    "self_employed_regex = ''\n",
    "\n",
    "for line in self_employed_keywords:\n",
    "    self_employed_regex += '(' + line +')|'\n",
    "\n",
    "self_employed_regex += '(self employ)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unemployed\n",
    "unemployed_keywords = ['not employ', 'at home', 'none', '0', 'home[ ]*maker']\n",
    "unemployed_regex = ''\n",
    "\n",
    "for line in unemployed_keywords:\n",
    "    unemployed_regex += '(' + line +')|'\n",
    "\n",
    "unemployed_regex += '(unemploy)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emergency Services\n",
    "emergency_keywords = ['fire[ ]*fighter']\n",
    "emergency_regex = ''\n",
    "\n",
    "for line in emergency_keywords:\n",
    "    emergency_regex += '(' + line +')|'\n",
    "\n",
    "emergency_regex += '(fire)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Government\n",
    "government_keywords = ['commonwealth of ma', 'reimbursement']\n",
    "government_regex = ''\n",
    "\n",
    "for line in government_keywords:\n",
    "    government_regex += '(' + line +')|'\n",
    "\n",
    "government_regex += '(government)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_industry(donor_name, occupation, employer): \n",
    "    text = str(donor_name) + ' ' + str(occupation) + ' ' + str(employer)\n",
    "    text = text.lower().replace(\":-,.'\", '')\n",
    "#     display(text)\n",
    "    if(re.search(law_enforcement_regex, text)):\n",
    "        return 'Law Enforcement'\n",
    "    if (re.search(education_regex, text)):\n",
    "        return 'Education'\n",
    "    if (re.search(realestate_regex, text)):\n",
    "        return 'Real Estate'\n",
    "    if (re.search(healthcare_regex, text)):\n",
    "        return 'Healthcare'\n",
    "    if (re.search(biotech_regex, text)):\n",
    "        return 'Biotech/Pharma'\n",
    "    if (re.search(energy_regex, text)):\n",
    "        return 'Energy'\n",
    "    if (re.search(emergency_regex, text)):\n",
    "        return 'Emergency Services'\n",
    "    if (re.search(retiree_regex, text)):\n",
    "        return 'Retired'\n",
    "    if (re.search(self_employed_regex, text)):\n",
    "        return 'Self-Employed'\n",
    "    if (re.search(unemployed_regex, text)):\n",
    "        return 'Unemployed'\n",
    "    if(re.search(government_regex, text)):\n",
    "        return 'Government'\n",
    "    # Case no match found\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAC keywords\n",
    "PAC_keywords = ['\\Wpac\\W', 'pol action', 'political action', 'committee', 'action']\n",
    "PAC_regex = ''\n",
    "\n",
    "for line in PAC_keywords:\n",
    "    PAC_regex += '(' + line +')|'\n",
    "\n",
    "PAC_regex += '(real estate)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union Keywords\n",
    "union_keywords = ['\\Wunion\\W', 'association']\n",
    "union_regex = ''\n",
    "\n",
    "for line in union_keywords:\n",
    "    union_regex += '(' + line +')|'\n",
    "\n",
    "union_regex += '(union pac)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lobbyist Keywords\n",
    "lobbyist_keywords = ['lobbyist']\n",
    "lobbyist_regex = ''\n",
    "\n",
    "for line in lobbyist_keywords:\n",
    "    lobbyist_regex += '(' + line +')|'\n",
    "\n",
    "lobbyist_regex += '(lobby)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate\n",
    "candidate_keywords = []\n",
    "candidate_regex = ''\n",
    "\n",
    "for line in candidate_keywords:\n",
    "    candidate_regex += '(' + line +')|'\n",
    "\n",
    "candidate_regex += '(reimbursement)'\n",
    "# display(regex_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def fuzzy_compare(str1, str2):\n",
    "#     display(str1 + ' == ' +str2)#debug\n",
    "    ratio = fuzz.ratio(str1.lower().replace(\":-,.'\", ''), str2.lower().replace(\":-,.'\", ''))\n",
    "#     display(ratio)#debug\n",
    "    if (ratio > 80):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_state_reps = pd.DataFrame(state_reps, columns = ['Representative'])\n",
    "# display(df_state_reps['Representative'].head())\n",
    "\n",
    "def find_PAC(donor_name, candidate_name): \n",
    "    text = ' ' + str(donor_name) + ' '\n",
    "    text = text.lower().replace(\":-,.'\", ' ')\n",
    "#     display(text)\n",
    "    # Note - Union checking must come before PAC because of \"union pac\"\n",
    "    if(re.search(union_regex, text)):\n",
    "        return 'Union'\n",
    "    if(re.search(PAC_regex, text)):\n",
    "        return 'PAC'\n",
    "    if(re.search(candidate_regex, text)):\n",
    "        return 'Candidate'\n",
    "    \n",
    "    candidateFound = fuzzy_compare(donor_name, candidate_name)\n",
    "#     display(candidateFound)\n",
    "    if (candidateFound):\n",
    "        return 'Candidate'\n",
    "    # Case no match found\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018_real['Industry'] = df_2018_real[['Donor_Name', 'Occupation', 'Employer']].apply(lambda x: find_industry(x[0], x[1], x[2]), axis=1)\n",
    "\n",
    "# df_2018_real['Industry'] = df_2018_real[df_2018_real.Occupation.notnull()]['Occupation'].apply(find_industry)\n",
    "# df_2018_real['Industry'] = df_2018_real[df_2018_real.Employer.notnull()]['Employer'].apply(find_industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018_real['PAC'] = df_2018_real[['Donor_Name', 'Full_Name']].apply(lambda x: find_PAC(x[0], x[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2018_real.loc[df_2018_real.PAC.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018_real.to_csv('/Data/contribution_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2018_real.loc[df_2018_real.Full_Name=='Robert A. DeLeo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
